{
 "nbformat": 4,
 "nbformat_minor": 5,
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1b2c3d4",
   "metadata": {},
   "source": "# MedGemma Trauma Analysis — Colab Test Runner\n**Branch:** `feature/deep-volume-qa`\n\nRun cells top-to-bottom. Steps:\n1. Install dependencies\n2. Clone repo & switch to feature branch\n3. Set tokens\n4. Export real RSNA trauma CT slices for testing\n5. (Optional) Clear GPU memory\n6. Launch Flask app via ngrok\n\nAfter launching, open the ngrok URL and upload files from `/content/sample_ct/` to test."
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c2d3e4",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 1 — Install dependencies\n# datasets must be pinned to <3.0.0 — newer versions dropped loading script support\n# which breaks the RSNA dataset used by export_sample_images.py\n!pip install -q \\\n    transformers>=4.47.0 \\\n    peft>=0.10.0 \\\n    bitsandbytes \\\n    accelerate \\\n    flask \\\n    flask-cors \\\n    pyngrok \\\n    nibabel \\\n    pydicom \\\n    segmentation-models-pytorch \\\n    sentencepiece \\\n    protobuf \\\n    \"datasets==2.21.0\""
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1d2e3f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2 — Clone repo & switch to feature branch\n",
    "!git clone https://github.com/AryanMarwah7781/medgemma-trauma-analysis\n",
    "%cd medgemma-trauma-analysis\n",
    "!git fetch origin\n",
    "!git switch feature/deep-volume-qa\n",
    "!git pull origin feature/deep-volume-qa\n",
    "!ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1e2f3a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3 — Set tokens (replace placeholders with your actual tokens)\n",
    "import os\n",
    "\n",
    "os.environ[\"HF_TOKEN\"]     = \"hf_YOUR_TOKEN_HERE\"        # huggingface.co/settings/tokens\n",
    "os.environ[\"NGROK_TOKEN\"]  = \"YOUR_NGROK_TOKEN_HERE\"     # dashboard.ngrok.com/authtokens\n",
    "os.environ[\"USE_NGROK\"]    = \"true\"\n",
    "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
    "\n",
    "# Optional: point to a saved LoRA adapter on Drive\n",
    "# os.environ[\"LORA_ADAPTER\"] = \"/content/drive/MyDrive/medgemma_lora/final_adapter\"\n",
    "\n",
    "print(\"Tokens set. HF_TOKEN starts with:\", os.environ[\"HF_TOKEN\"][:8])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f2a3b4",
   "metadata": {},
   "outputs": [],
   "source": "# Cell 4 — Export real labeled RSNA trauma CT slices\n# Pulls actual abdominal trauma CT volumes (liver, spleen, kidney injury + extravasation)\n# and saves them as PNG files ready to upload to the web UI.\n# Requires: HF_TOKEN set in Cell 3, and HuggingFace dataset terms accepted at\n#   https://huggingface.co/datasets/jherng/rsna-2023-abdominal-trauma-detection\n\n!python scripts/export_sample_images.py \\\n    --out_dir /content/sample_ct \\\n    --n 10 \\\n    --hf_token $HF_TOKEN\n\n# After this runs, check the manifest to see what injury types were exported:\n!cat /content/sample_ct/manifest.txt"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1a2b3c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5 — Clear GPU memory before launching (run if needed)\n",
    "import gc, torch\n",
    "gc.collect()\n",
    "torch.cuda.empty_cache()\n",
    "torch.cuda.reset_peak_memory_stats()\n",
    "print(f\"Free VRAM: {torch.cuda.mem_get_info()[0] / 1e9:.1f} GB\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b3c4d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6 — Launch Flask app with ngrok tunnel\n",
    "# The public URL will be printed below — open it in your browser\n",
    "!python app.py"
   ]
  }
 ]
}